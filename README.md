<h1 align="center">DeepSketch2Wear:Democratizing 3D Garment Creation via Freehand Sketches and Text</h1>

## ğŸ› ï¸ Installation

We recommend setting up an [Anaconda](https://www.anaconda.com/) environment using the provided `environment.yml` file:

```bash
conda env create -f environment.yml
conda activate DeepSketch2Wear
```

---

## ğŸ“¦ Data Preparation

Download the required datasets from the following link:

- [UDF & Sketch Data](https://pan.baidu.com/s/1-6MWddmB0DexTDrknT3swQ) (Password: `n5ty`)

### ğŸ”¹ UDF Data

Refer to the [UDiFF](https://github.com/weiqi-zhang/UDiFF/tree/main) to generate UDF fields from DeepFashion or your own data.

### ğŸ”¹ Sketch Data

Please refer to `prepare_sketch.py` for sketch data preprocessing instructions.

---

## ğŸ” Pre-trained Models

Pretrained weights are available [here](https://pan.baidu.com/s/1TKV73FX-seoTxUeWvtdpzQ) (Password: `pkrq`). After downloading, place them in the `result/` directory.

---

## ğŸš€ Training & Inference

### ğŸ¯ Stage 1: Base Diffusion Model

**Training:**

Training protocol will be released soon

**Inference:**

```bash
bash scripts/generate.sh
```
---

### âœ¨ Stage 2: Subdivision Diffusion Model

**Training:**

Training protocol will be released soon

**Inference:**

```bash
bash scripts/generate_super.sh
```

> ğŸ“ **Note:** All scripts are located in the `scripts/` directory. You can customize configurations by editing these scripts.

---

## ğŸ¨ Texture Generation

We recommend using [SyncMVD](https://github.com/LIU-Yuxin/SyncMVD) for high-quality texture generation.

### Step 1: Clone the SyncMVD Repository

```bash
git clone https://github.com/LIU-Yuxin/SyncMVD.git
cd SyncMVD
```

### Step 2: Environment Setup

Follow the installation and setup instructions provided in the SyncMVD repository.

### Step 3: Texture Inference

Use SyncMVD with the mesh outputs (located in `output/`) generated by our model.

---

## ğŸ“« Contact

For any issues or questions, feel free to open an issue or contact the authors.
